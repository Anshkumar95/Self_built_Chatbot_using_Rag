{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import fitz  # PyMuPDF\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model and NLTK stopwords\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MinIO connection (S3-compatible)\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url='http://localhost:9000',  # Adjust endpoint URL for MinIO\n",
    "    aws_access_key_id='admin',\n",
    "    aws_secret_access_key='admin123'\n",
    ")\n",
    "\n",
    "# Function to list PDF files from MinIO\n",
    "def list_pdf_files_from_minio(bucket_name):\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "    pdf_files = [item['Key'] for item in response.get('Contents', []) if item['Key'].endswith('.pdf')]\n",
    "    return pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from PDF using PyMuPDF (fitz)\n",
    "def extract_text_with_fitz(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page in doc:\n",
    "        full_text += page.get_text(\"text\")\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to process text\n",
    "def preprocess_text(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_sentence = [w for w in word_tokens if w.lower() not in stop_words]\n",
    "    doc = nlp(\" \".join(filtered_sentence))\n",
    "    processed_text = \" \".join([token.lemma_ for token in doc if not token.is_punct])\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download and process PDFs\n",
    "def download_and_process_pdf(file_name, bucket_name='raw-reports'):\n",
    "    # Download the file from MinIO\n",
    "    local_file = f'/tmp/{file_name}'\n",
    "    s3_client.download_file(bucket_name, file_name, local_file)\n",
    "\n",
    "    # Extract text from the downloaded PDF\n",
    "    full_text = extract_text_with_fitz(local_file)\n",
    "\n",
    "    # Preprocess the extracted text\n",
    "    processed_text = preprocess_text(full_text)\n",
    "\n",
    "    # Clean up by removing the local file\n",
    "    os.remove(local_file)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save processed text to MinIO or locally\n",
    "def save_processed_text(file_name, processed_text, bucket_name='processed-reports'):\n",
    "    local_processed_file = f'/tmp/processed_{file_name}.txt'\n",
    "    \n",
    "    # Save the processed text locally first\n",
    "    with open(local_processed_file, 'w') as f:\n",
    "        f.write(processed_text)\n",
    "\n",
    "    # Upload processed file to MinIO\n",
    "    s3_client.upload_file(local_processed_file, bucket_name, f'processed_{file_name}.txt')\n",
    "\n",
    "    # Remove local processed file\n",
    "    os.remove(local_processed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save metadata to SQLite\n",
    "def save_metadata_to_sqlite(file_name, file_size, features):\n",
    "    conn = sqlite3.connect('metadata.db')\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Create the metadata table if it doesn't exist\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS file_metadata\n",
    "                 (filename TEXT, processed_date TEXT, size INTEGER, features TEXT)''')\n",
    "\n",
    "    # Insert metadata\n",
    "    processed_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    c.execute(\"INSERT INTO file_metadata VALUES (?, ?, ?, ?)\",\n",
    "              (file_name, processed_date, file_size, features))\n",
    "\n",
    "    # Commit and close\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main processing loop\n",
    "def main():\n",
    "    # List all PDF files from the MinIO bucket\n",
    "    pdf_files = list_pdf_files_from_minio('raw-reports')\n",
    "\n",
    "    for file_name in pdf_files:\n",
    "        # Download and process each PDF\n",
    "        processed_text = download_and_process_pdf(file_name)\n",
    "\n",
    "        # Save processed text back to MinIO\n",
    "        save_processed_text(file_name, processed_text)\n",
    "\n",
    "        # Calculate file size and example features (e.g., keyword extraction)\n",
    "        file_size = len(processed_text.encode('utf-8'))  # Size in bytes\n",
    "        features = 'keywords: AI, ML'  # Example features (can be expanded)\n",
    "\n",
    "        # Save metadata to SQLite\n",
    "        save_metadata_to_sqlite(file_name, file_size, features)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
